# 2BMux: 2b-RAD Demultiplexing and Sample Sheet Generation Toolkit

This repository contains a set of scripts designed to process raw, multiplexed 2b-RAD sequencing data. The workflow allows you to demultiplex FASTQ files based on inline barcodes, generate the necessary sample mapping files, and prepare your data for downstream analysis tools like `ipyrad`.

## Overview

This toolkit includes three main components:

1.  **`2BMux.py`**: The core script that performs demultiplexing. It identifies reads based on in-line barcodes in R1 reads and associates R2 reads with their corresponding R1 reads for paired-end output. Demultiplexed reads are then quality filtered, and renamed based on the index sample name mapping file generated by PlateRelate.py.
2.  **`2BMux_memopt.py`**: A memory-optimized version of `2BMux.py`, designed for processing very large datasets where the original script might encounter out-of-memory errors. It achieves this by streaming reads to disk rather than holding them all in RAM.
3.  **`PlateRelate.py`**: A helper script to create a properly formatted sample-to-barcode map (`-idmap` file). It takes a simple plate layout matrix and a list of sample names and generates the detailed CSV file required by the main demultiplexing script.
4.  **`concatenatepairs.sh`**: A utility shell script to concatenate paired-end (R1/R2) FASTQ files into a single file per sample. This is often required for downstream tools like `ipyrad` that use a single-end assembly workflow for 2b-RAD data.

## General Workflow

The recommended workflow is as follows:

1.  **Prepare Sample Information**: Create your input files:
    *   A CSV file listing your `SampleID` and a unique `Index` for each (e.g., `Plate1_Samples_input.csv`).
    *   A CSV file representing your physical plate layout, using the indices from the file above (e.g., `Plate1Matrix_input.csv`).

2.  **Generate the ID Map**: Use `PlateRelate.py` to convert your plate layout and sample list into the final `PlateX_IDs.csv` file. This file maps each sample to its specific plate, row, and barcode.

3.  **Demultiplex Raw Data**: Run either the original `2BMux.py` or the memory-optimized `2bmux_memopt.py` script on your raw, multiplexed `R1` and `R2` FASTQ files, using the `PlateX_IDs.csv` file as the `-idmap` input. This will produce clean, demultiplexed FASTQ files for each sample.

4.  **(Optional) Merge Paired-End Files**: If your downstream analysis requires it, use the `concatenatepairs.sh` script to combine the demultiplexed `_R1_.fastq` and `_R2_.fastq` files into a single merged FASTQ file for each sample.

---

## 1. `PlateRelate.py` - Sample Sheet Generator

This script automates the creation of the sample-to-barcode mapping file required by the main demultiplexer. It translates a simple plate layout into the exact format needed for the 2BMux.py script -idmap input.

### Features

*   Parses a simple CSV matrix representing your 8-row plate.
*   Handles plates with a variable number of columns (up to 12).
*   Ignores empty cells or cells with non-numeric text (e.g., "Blank").
*   Maps the column position to a pre-defined 4-bp barcode. This can be changed by hardcoding the barcodes in the scripts.
*   Accepts command-line arguments for plate number and input files.
*   For multiple plates, run the script independently for each plate, using the proper plate number, and then concatenate output files for each and remove extra headers.

### Usage

```sh
python PlateRelate.py -plate 1 -matrix Plate1Matrix_input.csv -ids Plate1_Samples_input.csv
```

**Arguments:**

*   `-plate`: (Required) An integer representing the plate number (e.g., `1`).
*   `-matrix`: (Required) Path to your plate layout CSV file. This file should have **no headers** and contain sample indices in an 8-row, up to 12-column format.
*   `-ids`: (Required) Path to your csv containing sample IDs and their corresponding index number. This file **must have headers** `SampleID` and `Index`.

### Example

**Input File 1: `Plate1_Samples_input.csv` (`-ids`)**
```csv
SampleID,Index
Sample_A,1
Sample_B,2
Sample_C,3
etc...
```

**Input File 2: `Plate1Matrix_input.csv` (`-matrix`)**
```csv
1,2,3
13,14,Blank,16
```

**Command:**
```sh
python PlateRelate.py -plate 1 -matrix plate1matrix.csv -ids samples.csv
```

**Output File: `Plate1_IDs.csv`**
```csv
Plate,Row,3illBC,SampleID
1,1,ACAC,Sample_A
1,1,GTCT,Sample_B
1,1,TGGT,Sample_C
```

---

## 2. `2BMux.py` - The Demultiplexer

`2BMux.py` is designed to demultiplex 2bRAD sequencing data, perform quality filtering, as well as barcode and adapter trimming. The script generates summary statistics for each sample across rows for each plate. It handles both R1 and R2 reads, associating them based on R1 barcode identification.

### Features

*   Identifies samples based on in-line barcodes in R1 reads.
*   Associates R2 reads with their corresponding R1 reads for paired-end output.
*   Removes identified 4bp in-line barcodes from both R1 and R2 reads.
*   Trims potential adapter read-through (e.g., `AGAT` motif) from R2 reads.
*   Ensures final reads conform to expected fragment sizes (e.g., 36bp).
*   Applies `fastq_quality_filter` from FASTX-Toolkit (must be preinstalled) for quality trimming and filtering.
*   Generates a CSV report with read counts, barcode orientation statistics, and read length distributions per sample.
*   Separates reads with unidentifiable barcodes into dedicated directories.
*   Allows customization of barcode regex, adapter sequences, trimming lengths, and minimum read counts.

### Dependencies

*   Python 3.x
*   `fastq_quality_filter` (from FASTX-Toolkit) - Recommended for quality filtering. If not found, the script will still gzip output but without quality filtering.

### Usage

```bash
python 2BMux.py \
    -plate <position_of_plate_in_filename> \
    -row <position_of_row_in_filename> \
    -read <position_of_read_type_in_filename> \
    -idmap <path_to_idmap_csv> \
    [--strict_orientation] \
    [--antiBC_only] \
    [-site <regex_for_fragment>] \
    [-barcode <regex_for_barcode>] \
    [-adaptor <R1_adaptor_sequence>] \
    [-trim <bases_to_trim_from_ends>] \
    [-min_bc_count <minimum_reads_per_barcode>]
```

**Arguments:**

*   `-plate`, `-row`, `-read`: Integers specifying the underscore delimited position of the plate number, row number, and read type (R1/R2) in your input FASTQ filenames (e.g., `Sample_Plate1_RowA_R1.fastq.gz` -> `-plate 2 -row 3 -read 4`).
*   `-idmap`: Path to a CSV file mapping samples to their plate, row, and 3illBC barcode, can be generated by PlateRelate.py. **Must have headers: `Plate`, `Row`, `3illBC`, `SampleID`**.
*   `--strict_orientation`: (Optional flag) If set, reads with an unexpected site/barcode orientation (e.g., a forward read with an anti-barcode) will be discarded.
*   `--antiBC_only`: (Optional flag) If set, the script will *only* consider observed anti-barcodes for demultiplexing. The `idmap`'s `3illBC` column is still used as the sample identifier, but the script will look for its corresponding anti-barcode in the reads.
*   `-site`: Regular expression for the DNA fragment. Default: `^(?:(?P<forward>.{36})|(?P<reverse>.{36}))` (matches 36bp fragment at the beginning of read, doesn't disambiguate forward/reverse orientation in summary table). Use '(?:(?P<forward>.{12}CGA.{6}TGC.{12})|(?P<reverse>.{12}GCA.{6}TCG.{12}))' for a strict identification of BCGI enzyme cut sites in forward/reverse directions to identify reads, which will populate Fwd/Rev columns in the summary statistics table.
*   `-barcode`: Regular expression for the in-line barcode. Default: `[ATGC]{4}` (matches any 4-bp sequence of ATGC).
*   `-adaptor`: Partial P7 adapter sequence on R1. Default: `AGATCGGAAG`.
*   `-trim`: Number of bases to symmetrically trim from both ends of the final fragment. Default: `0`.
*   `-min_bc_count`: Minimum number of reads required for a barcode to be considered a valid sample. Barcodes below this threshold will be treated as unmatched. Default: `10000`.

### Detailed Workflow Explanation

The script processes input gzipped FASTQ files in pairs (R1 and R2) and performs a series of steps to demultiplex and clean the reads.

1.  **Input File Parsing and Pairing:** The script first identifies all `*.fastq.gz` or `*.fq.gz` files in the current directory. It then uses the provided `-plate`, `-row`, and `-read` arguments to parse the filenames and group R1 and R2 files belonging to the same plate and row.

2.  **ID Map Loading and Demultiplexing Strategy:** The `-idmap` CSV file defines the expected `3illBC` barcode for each sample at a given plate and row. Based on the presence of the `--antiBC_only` flag, the script sets up an internal `demux_map`:
    *   **Default Mode (no `--antiBC_only`):** The `demux_map` allows an observed barcode (from the read) to be either the `3illBC` or its `antiBC`. Both will map to the official `3illBC` for that sample.
    *   **`--antiBC_only` Mode:** The `demux_map` is configured such that *only* observed `antiBC`s will map to their corresponding `3illBC`s.

3.  **R1 Read Processing (Demultiplexing and Initial Trimming):** For each R1 read, the script performs the following:
    *   **Fragment and Barcode Identification:** It uses the `-site` regex (defaulting to a 36bp fragment) to identify the DNA fragment and the subsequent 4bp barcode. It also determines the fragment's `orientation` (forward or reverse).
    *   **Barcode Validation:** It checks if the identified 4bp sequence matches the `-barcode` regex and if the sequence immediately following the barcode matches the `-adaptor` sequence.
    *   **Target Barcode Assignment:** The `obs_bc` (observed barcode) is then used with the `demux_map` to determine the `target_bc` (the official `3illBC` for the sample). This is where the `--antiBC_only` logic is applied.
    *   **Strict Orientation Check (if `--strict_orientation`):** If this flag is set, and the `orientation` of the fragment does not match the expected orientation for the `obs_bc` (e.g., a forward fragment with an anti-barcode), the read is marked as invalid and discarded.
    *   **Read Bucketing:** Valid reads are assigned to an internal data structure (`r1_data`) keyed by their `target_bc`. Read IDs are stored to link R1 and R2 reads.
    *   **R1 Trimming:** The 36bp fragment identified by the `-site` regex is extracted. Any additional symmetric trimming specified by `-trim` is applied.
    *   **Summary Counting:** The script tracks how many reads for each `target_bc` were observed with specific orientations (e.g., `SiteFwd_3ill`, `SiteFwd_anti`).

4.  **R2 Read Processing (Association and Advanced Trimming):** For each R2 read, the script performs:
    *   **R1 Association:** It uses the read ID to find its corresponding R1 read and the `target_bc` that was assigned to that R1 read. If no R1 match or the R1 was unmatched, the R2 read is skipped.
    *   **R2 Trimming - Adapter Motif:** If the R2 read is longer than 36bp, it checks the last 10bp for the `AGAT` adapter motif. If found, it trims the read from that point. This handles partial adapter read-through.
    *   **R2 Trimming - Barcode:** It then attempts to trim the 4bp `target_bc` (or its reverse complement) from *both* ends of the R2 read. This accounts for potential barcode presence due to library preparation or sequencing artifacts.
    *   **Strict Length Filtering:** After all trimming attempts, if the R2 read is *still* longer than the expected fragment size, it is discarded. This ensures only fragments of the expected length proceed.
    *   **Final R2 Trimming:** Any additional symmetric trimming specified by `-trim` is applied.

5.  **Output Generation:**
    *   **Unmatched Barcodes:** Reads assigned to `UNMATCHED_` barcodes (either due to no match or falling below `-min_bc_count`) are written to separate `unmatched_barcodes_PlateXRowY` directories for manual inspection.
    *   **Sample FASTQ Files:** For each valid sample (meeting `-min_bc_count` and having an entry in the `idmap`):
        *   Temporary unzipped FASTQ files are created.
        *   `fastq_quality_filter` is run on these files (if available on the system) to perform quality trimming and filtering.
        *   The resulting files are then gzipped and saved as `SampleID_R1_.fastq.gz` and `SampleID_R2_.fastq.gz`.
    *   **Summary CSV:** A `PlateX_RowY_barcode_summary.csv` file is generated for each plate and row. This file includes:
        *   `3illBC`: The official 3illBC barcode.
        *   `SampleID`: The associated sample name from the `idmap`.
        *   `TotalReads`: Total reads assigned to this sample.
        *   `SiteFwd_3ill`, `SiteFwd_anti`, `SiteRev_anti`, `SiteRev_3ill`: Counts of reads based on fragment orientation and barcode type (3illBC or antiBC).
        *   `R1_len_mean`, `R1_len_stdev`, `R2_len_mean`, `R2_len_stdev`: Mean and standard deviation of read lengths for R1 and R2 reads after all trimming.

### Important Considerations

*   **Filename Consistency:** The script depends on consistent filename parsing. Ensure your input FASTQ files follow a predictable naming convention that allows the `-plate`, `-row`, and `-read` arguments to correctly extract information.
*   **Barcode Definitions:** The `BARCODE_PAIRS` dictionary at the top of the script defines the expected 3illBC and antiBC pairs. Ensure this matches your library preparation. You can hardcode your own barcode pairs if needed.
*   **`fastq_quality_filter`:** While optional, its presence is highly recommended for robust quality control. Install FASTX_Toolkit (e.g., via `conda install bioconda::fastx_toolkit`) if you intend to use its functionality.
*   **Memory Usage:** For very large datasets, the default main script 2BMux.py stores all reads in memory before writing them to disk. Consider using the 2BMux_memopt.py if you are running into memory issues.

---

## 2.1. `2bmux_memopt.py` - Memory-Optimized Demultiplexer

`2bmux_memopt.py` is a specialized version of the demultiplexing script designed to address high memory consumption when processing extremely large sequencing datasets. It maintains all the core functionality and output of the original `2BMux.py` but employs a streaming approach to minimize RAM usage.

### Key Memory Optimizations

This version implements the following major memory-saving strategies:

*   **Elimination of In-Memory Read Storage**: Unlike `2BMux.py`, which accumulates all demultiplexed reads in `r1_data` and `r2_data` dictionaries before writing, `2bmux_memopt.py` writes each successfully processed read directly to its respective temporary output file as it is encountered. This prevents the massive accumulation of read data in RAM.
*   **Optimized Statistics Calculation**: Instead of storing lists of all read lengths and quality scores (`r1_quals`, `r2_quals`), this script calculates running sums and counts for these metrics. This allows for the computation of mean and standard deviation without holding individual data points in memory, significantly reducing the memory footprint for statistical tracking.
*   **Streamlined File Handling**: Output files for each sample are opened incrementally and written to as reads are processed.

### Usage

The command-line arguments and overall usage for `2bmux_memopt.py` are identical to `2BMux.py`:

```bash
python 2bmux_memopt.py \
    -plate <position_of_plate_in_filename> \
    -row <position_of_row_in_filename> \
    -read <position_of_read_type_in_filename> \
    -idmap <path_to_idmap_csv> \
    [--antiBC_only] \
    [-site <regex_for_fragment>] \
    [-barcode <regex_for_barcode>] \
    [-adaptor <R1_adaptor_sequence>] \
    [-trim <bases_to_trim_from_ends>] \
    [-min_bc_count <minimum_reads_per_barcode>]
```


**Recommendation:**

*   Use **`2BMux.py`** if you have sufficient RAM and are processing datasets that do not cause out-of-memory issues. It might offer slightly faster execution for smaller jobs.
*   Use **`2bmux_memopt.py`** if you are encountering out-of-memory errors with `2BMux.py`, or if you are working with exceptionally large datasets where memory efficiency is paramount. Be aware that processing time might be longer due to increased disk I/O.

---

## 3. `concatenatepairs.sh` - FASTQ Merger

A simple shell script to concatenate R1 and R2 files into a single merged file, which is a requirement for `ipyrad`'s `2brad` assembly mode.

### Features

*   Automatically finds all `_R1` files in a directory.
*   Handles both `.fastq` and `.fastq.gz` files.
*   Constructs the corresponding `_R2` and output filenames.
*   Does not delete original files.

### Usage

1.  Place the script in the directory containing your demultiplexed FASTQ files.
2.  Make it executable: `chmod +x concatenatepairs.sh`
3.  Run it: `bash concatenatepairs.sh`

### Example

**If your directory contains:**
*   `SampleA_R1_.fastq.gz`
*   `SampleA_R2_.fastq.gz`

**After running the script, you will have a new file:**
*   `SampleA.fastq.gz`

